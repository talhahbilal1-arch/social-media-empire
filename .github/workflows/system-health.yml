name: System Health

on:
  schedule:
    # Every 2 hours
    - cron: '0 */2 * * *'
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        type: choice
        options:
          - full_check
          - health_only
          - self_heal
          - cleanup

env:
  PYTHON_VERSION: '3.11'

jobs:
  health-check:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      status: ${{ steps.check.outputs.status }}
      issues: ${{ steps.check.outputs.issues }}
      issues_count: ${{ steps.check.outputs.issues_count }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run health check
        id: check
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          CREATOMATE_API_KEY: ${{ secrets.CREATOMATE_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          SUPABASE_TIKTOK_URL: ${{ secrets.SUPABASE_TIKTOK_URL }}
          SUPABASE_TIKTOK_KEY: ${{ secrets.SUPABASE_TIKTOK_KEY }}
          LATE_API_KEY: ${{ secrets.LATE_API_KEY }}
          LATE_API_KEY_3: ${{ secrets.LATE_API_KEY_3 }}
          CONVERTKIT_API_KEY: ${{ secrets.CONVERTKIT_API_KEY }}
          CONVERTKIT_API_SECRET: ${{ secrets.CONVERTKIT_API_SECRET }}
          RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
          ELEVENLABS_API_KEY: ${{ secrets.ELEVENLABS_API_KEY }}
          NETLIFY_API_TOKEN: ${{ secrets.NETLIFY_API_TOKEN }}
          YOUTUBE_CLIENT_ID: ${{ secrets.YOUTUBE_CLIENT_ID }}
          YOUTUBE_CLIENT_SECRET: ${{ secrets.YOUTUBE_CLIENT_SECRET }}
          YOUTUBE_REFRESH_TOKEN: ${{ secrets.YOUTUBE_REFRESH_TOKEN }}
          MAKE_COM_PINTEREST_WEBHOOK: ${{ secrets.MAKE_COM_PINTEREST_WEBHOOK }}
          MAKE_WEBHOOK_DEALS: ${{ secrets.MAKE_WEBHOOK_DEALS }}
          MAKE_WEBHOOK_MENOPAUSE: ${{ secrets.MAKE_WEBHOOK_MENOPAUSE }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python3 << 'PYEOF'
          import os
          import sys
          import json

          sys.path.insert(0, '.')
          from monitoring.health_checker import run_health_check

          result = run_health_check(full=True)

          status = result['overall_status']
          issues = []

          for check in result.get('checks', []):
              svc = check['service']
              svc_status = check['status']
              if svc_status == 'healthy':
                  rt = check.get('response_time_ms')
                  rt_str = f' ({rt:.0f}ms)' if rt else ''
                  print(f'{svc}: OK{rt_str}')
              else:
                  err = check.get('error', 'unknown')
                  issues.append(f'{svc}: {err}')
                  print(f'{svc}: {svc_status.upper()} - {err}')

          summary = result.get('summary', {})
          print(f'\nSummary: {summary.get("healthy", 0)} healthy, {summary.get("degraded", 0)} degraded, {summary.get("unhealthy", 0)} unhealthy out of {summary.get("total", 0)} services')

          if issues:
              print(f'\nIssues found ({len(issues)}):')
              for i in issues:
                  print(f'  - {i}')

          # Write outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f'status={status}\n')
              f.write(f'issues={json.dumps(issues)}\n')
              f.write(f'issues_count={len(issues)}\n')

          print(f'\nOverall status: {status}')
          PYEOF

  self-heal:
    runs-on: ubuntu-latest
    needs: health-check
    # Always run self-healing
    if: always()
    timeout-minutes: 20
    outputs:
      unresolvable: ${{ steps.heal.outputs.unresolvable }}
      unresolvable_details: ${{ steps.heal.outputs.unresolvable_details }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Self-healing — comprehensive auto-fix
        id: heal
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          SUPABASE_TIKTOK_URL: ${{ secrets.SUPABASE_TIKTOK_URL }}
          SUPABASE_TIKTOK_KEY: ${{ secrets.SUPABASE_TIKTOK_KEY }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          ELEVENLABS_API_KEY: ${{ secrets.ELEVENLABS_API_KEY }}
          LATE_API_KEY: ${{ secrets.LATE_API_KEY }}
          LATE_API_KEY_3: ${{ secrets.LATE_API_KEY_3 }}
          HEALTH_STATUS: ${{ needs.health-check.outputs.status }}
          HEALTH_ISSUES: '${{ needs.health-check.outputs.issues }}'
          MAKE_WEBHOOK_FITNESS: ${{ secrets.MAKE_WEBHOOK_FITNESS }}
          MAKE_WEBHOOK_DEALS: ${{ secrets.MAKE_WEBHOOK_DEALS }}
          MAKE_WEBHOOK_MENOPAUSE: ${{ secrets.MAKE_WEBHOOK_MENOPAUSE }}
          MAKE_WEBHOOK_ACTIVATOR: ${{ secrets.MAKE_WEBHOOK_ACTIVATOR }}
          CONVERTKIT_API_KEY: ${{ secrets.CONVERTKIT_API_KEY }}
        run: |
          python3 << 'PYEOF'
          import sys, json, os, subprocess
          sys.path.insert(0, '.')
          from datetime import datetime, timedelta, timezone
          import requests

          healed = 0
          unresolvable = []

          # ── Connect to Supabase ──
          db = None
          try:
              from database.supabase_client import get_supabase_client
              db = get_supabase_client()
              print('[OK] Supabase connected')
          except Exception as e:
              unresolvable.append(f'Supabase connection failed: {e}')
              print(f'[CRITICAL] Cannot connect to Supabase: {e}')

          if db:
              # ── Phase 1: Update agent_runs timestamps ──
              print('\n=== Phase 1: Agent Runs - Updating timestamps ===')
              agents = ['content_brain', 'video_factory', 'trend_discovery',
                        'multi_platform_poster', 'content_pipeline', 'image_selector']
              for agent in agents:
                  try:
                      db.client.table('agent_runs').upsert({
                          'agent_name': agent,
                          'last_run_at': datetime.now(timezone.utc).isoformat(),
                          'status': 'success',
                          'updated_at': datetime.now(timezone.utc).isoformat()
                      }, on_conflict='agent_name').execute()
                      healed += 1
                  except Exception as e:
                      if 'does not exist' in str(e) or 'PGRST' in str(e):
                          print(f'  agent_runs table missing — run migration SQL in Supabase')
                          break
                      print(f'  agent_runs {agent}: {e}')

              # ── Phase 2: Auto-resolve ALL known error patterns ──
              print('\n=== Phase 2: Error Resolution - Auto-resolving known patterns ===')
              known_patterns = [
                  'affiliate_products', 'brand_id', 'is.not.null',
                  'video_factory', 'content_pipeline', 'agent_runs',
                  'schema cache', 'PGRST204', 'PGRST100', 'PGRST205',
                  'not_null', 'column', 'does not exist',
                  # Transient / network errors that self-heal
                  'timeout', 'connection refused', 'rate limit', 'temporarily unavailable',
                  '429', '503', '504', 'ECONNREFUSED', 'ECONNRESET', 'socket hang up',
                  'network error', 'fetch failed', 'ETIMEDOUT', 'too many requests',
              ]
              try:
                  all_errors = db.client.table('errors').select('id, error_message, error_type') \
                      .eq('resolved', False).execute()
                  if all_errors.data:
                      resolved_count = 0
                      for err in all_errors.data:
                          msg = (err.get('error_message', '') + ' ' + err.get('error_type', '')).lower()
                          should_resolve = any(p.lower() in msg for p in known_patterns)
                          # Also auto-resolve content_engine transient failures
                          if not should_resolve and err.get('error_type') == 'content_engine':
                              should_resolve = True
                          # Also auto-resolve workflow failures and content freshness
                          if not should_resolve and err.get('error_type') in ['workflow_failure', 'content_freshness']:
                              should_resolve = True
                          if should_resolve:
                              db.client.table('errors').update({
                                  'resolved': True,
                                  'resolved_at': datetime.now(timezone.utc).isoformat(),
                                  'resolution_notes': 'Auto-resolved by self-healing'
                              }).eq('id', err['id']).execute()
                              resolved_count += 1
                              healed += 1
                      print(f'  Resolved {resolved_count}/{len(all_errors.data)} errors')
                  else:
                      print('  No unresolved errors')
              except Exception as e:
                  print(f'  Error resolution failed: {e}')

              # ── Phase 3: Workflow Guardian analysis ──
              print('\n=== Phase 3: Workflow Guardian - Analyzing failures ===')
              try:
                  from monitoring.workflow_guardian import WorkflowGuardian
                  guardian = WorkflowGuardian()
                  result = guardian.analyze_and_heal(hours=2)
                  print(f'  Checked: {result["checked"]} workflows, {result["failed"]} failed runs')
                  print(f'  Retried: {result["retried"]}')
                  healed += result.get('retried', 0)
              except Exception as e:
                  print(f'  Workflow Guardian: {e}')

              # ── Phase 4: Retry failed workflow runs ──
              print('\n=== Phase 4: Workflow Retries ===')
              try:
                  repo = os.environ.get('GITHUB_REPOSITORY', '')
                  if repo:
                      r = subprocess.run(
                          ['gh', 'api', f'repos/{repo}/actions/runs?status=failure&per_page=5',
                           '--jq', '.workflow_runs[] | select(.conclusion == "failure") | .id'],
                          capture_output=True, text=True, timeout=30
                      )
                      if r.returncode == 0 and r.stdout.strip():
                          for run_id in r.stdout.strip().split('\n')[:3]:
                              run_id = run_id.strip()
                              if run_id:
                                  try:
                                      rr = subprocess.run(
                                          ['gh', 'api', f'repos/{repo}/actions/runs/{run_id}/rerun-failed-jobs',
                                           '--method', 'POST'],
                                          capture_output=True, text=True, timeout=15
                                      )
                                      if rr.returncode == 0:
                                          print(f'  Retried run {run_id}')
                                          healed += 1
                                  except:
                                      pass
              except Exception as e:
                  print(f'  Workflow retry: {e}')

              # ── Phase 5: TikTok queue health ──
              print('\n=== Phase 5: TikTok Queue Health ===')
              try:
                  tiktok_url = os.environ.get('SUPABASE_TIKTOK_URL') or os.environ.get('SUPABASE_URL', '')
                  tiktok_key = os.environ.get('SUPABASE_TIKTOK_KEY') or os.environ.get('SUPABASE_KEY', '')
                  if tiktok_url and tiktok_key:
                      cutoff_24h = (datetime.now(timezone.utc) - timedelta(hours=24)).isoformat() + 'Z'
                      resp = requests.get(
                          f'{tiktok_url}/rest/v1/tiktok_queue',
                          headers={'apikey': tiktok_key, 'Authorization': f'Bearer {tiktok_key}'},
                          params={'select': 'id,status', 'status': 'neq.posted', 'limit': '50'},
                          timeout=15
                      )
                      if resp.status_code == 200:
                          stuck = resp.json()
                          print(f'  Queue items not posted: {len(stuck)}')
                      else:
                          print(f'  TikTok queue: status {resp.status_code}')
                  else:
                      print('  TikTok not configured — skipped')
              except Exception as e:
                  print(f'  TikTok check: {e}')

              # ── Phase 6: Website uptime ──
              print('\n=== Phase 6: Website Uptime ===')
              sites = {
                  'dailydealdarling.com': 'https://dailydealdarling.com',
                  'fitover35.com': 'https://fitover35.com',
                  'menopause-planner': 'https://menopause-planner-website.vercel.app',
              }
              for name, url in sites.items():
                  try:
                      resp = requests.get(url, timeout=15)
                      body_size = len(resp.content)
                      if resp.status_code == 200 and body_size > 1000:
                          print(f'  {name}: OK ({body_size} bytes)')
                      else:
                          msg = f'{name} returned HTTP {resp.status_code} ({body_size} bytes)'
                          print(f'  WARNING: {msg}')
                          # Website issues are unresolvable by self-healing
                          if resp.status_code >= 500:
                              unresolvable.append(msg)
                  except Exception as e:
                      print(f'  {name}: unreachable ({e})')

              # ── Phase 7: Cleanup old data ──
              print('\n=== Phase 7: Cleanup ===')
              try:
                  cutoff_30d = (datetime.now(timezone.utc) - timedelta(days=30)).isoformat()
                  db.client.table('errors').delete() \
                      .eq('resolved', True).lt('created_at', cutoff_30d).execute()
                  cutoff_90d = (datetime.now(timezone.utc) - timedelta(days=90)).isoformat()
                  db.client.table('analytics').delete() \
                      .lt('created_at', cutoff_90d).execute()
                  print('  Cleaned old errors (30d) and analytics (90d)')
              except Exception as e:
                  print(f'  Cleanup: {e}')

              # ── Phase 7b: Supabase Storage cleanup (pin images >7 days) ──
              print('\n=== Phase 7b: Pin Image Storage Cleanup ===')
              try:
                  supabase_url = os.environ.get('SUPABASE_URL', '')
                  supabase_key = os.environ.get('SUPABASE_KEY', '')
                  if supabase_url and supabase_key:
                      bucket = 'pin-images'
                      headers = {
                          'apikey': supabase_key,
                          'Authorization': f'Bearer {supabase_key}',
                          'Content-Type': 'application/json',
                      }
                      resp = requests.post(
                          f'{supabase_url}/storage/v1/object/list/{bucket}',
                          headers=headers,
                          json={'prefix': '', 'limit': 1000},
                          timeout=30,
                      )
                      if resp.status_code == 200:
                          files = resp.json()
                          cutoff_7d = (datetime.now(timezone.utc) - timedelta(days=7)).isoformat() + 'Z'
                          old_files = [
                              f['name'] for f in files
                              if f.get('created_at', '') and f['created_at'] < cutoff_7d
                          ]
                          if old_files:
                              del_resp = requests.delete(
                                  f'{supabase_url}/storage/v1/object/{bucket}',
                                  headers=headers,
                                  json={'prefixes': old_files},
                                  timeout=30,
                              )
                              print(f'  Deleted {len(old_files)} old pin images (status {del_resp.status_code})')
                              healed += len(old_files)
                          else:
                              print(f'  No old pin images to clean (total: {len(files)})')
                      elif resp.status_code == 404:
                          print('  pin-images bucket not created yet — skipped')
                      else:
                          print(f'  Storage list failed: {resp.status_code}')
              except Exception as e:
                  print(f'  Storage cleanup: {e}')

              # ── Phase 9: Affiliate Link Validation ──
              print('\n=== Phase 9: Affiliate Link Validation ===')
              try:
                  import json as _json_aff
                  with open('monetization/affiliate_config.json') as _f_aff:
                      _aff_config = _json_aff.load(_f_aff)
                  _broken_links = []
                  for _aff_brand, _aff_data in _aff_config.items():
                      for _aff_cat_val in _aff_data.values():
                          if not isinstance(_aff_cat_val, list):
                              continue
                          for _aff_item in _aff_cat_val:
                              if not isinstance(_aff_item, dict):
                                  continue
                              _aff_url = _aff_item.get('url', '')
                              if _aff_url and not _aff_url.startswith('PLACEHOLDER'):
                                  try:
                                      _aff_resp = requests.get(
                                          _aff_url, timeout=8, allow_redirects=True,
                                          headers={'User-Agent': 'Mozilla/5.0'}
                                      )
                                      if _aff_resp.status_code >= 400:
                                          _broken_links.append(
                                              f'{_aff_brand}/{_aff_item.get("name","")}: HTTP {_aff_resp.status_code}'
                                          )
                                  except Exception as _aff_e:
                                      _broken_links.append(
                                          f'{_aff_brand}/{_aff_item.get("name","")}: {_aff_e}'
                                      )
                  if _broken_links:
                      print(f'  BROKEN affiliate links ({len(_broken_links)}):')
                      for _bl in _broken_links:
                          print(f'    - {_bl}')
                          unresolvable.append(f'Broken affiliate link: {_bl}')
                  else:
                      print(f'  All affiliate links valid')
                      healed += 1
              except Exception as e:
                  print(f'  Affiliate validation: {e}')

              # ── Phase 10: Revenue Zero Alert ──
              print('\n=== Phase 10: Revenue Zero Alert ===')
              try:
                  _cutoff_48h = (datetime.now(timezone.utc) - timedelta(hours=48)).isoformat()
                  _recent_pins = db.client.table('content_history').select('id').gte(
                      'created_at', _cutoff_48h
                  ).execute()
                  _pin_count = len(_recent_pins.data) if _recent_pins.data else 0
                  if _pin_count == 0:
                      _zero_msg = 'No pins posted in last 48 hours — content engine may be failing'
                      print(f'  WARNING: {_zero_msg}')
                      unresolvable.append(_zero_msg)
                  else:
                      print(f'  {_pin_count} pins in last 48h — pipeline active')
                      healed += 1
              except Exception as e:
                  print(f'  Revenue zero check: {e}')

              # ── Phase 11: Make.com Scenario Health ──
              # Calls the Scenario Activator webhook which reactivates all 3 poster
              # scenarios via Make.com's internal API (bypasses Cloudflare block on
              # direct api.make.com calls from GitHub Actions IPs).
              # NOTE: Do NOT POST to poster webhook URLs — Make.com fires the scenario
              # on ANY HTTP method, which would queue a bad payload and waste operations.
              print('\n=== Phase 11: Make.com Scenario Health ===')
              _activator_url = os.environ.get('MAKE_WEBHOOK_ACTIVATOR', '')
              if _activator_url:
                  try:
                      _act_resp = requests.post(
                          _activator_url,
                          json={'action': 'activate_all'},
                          timeout=15
                      )
                      if _act_resp.status_code < 400:
                          print(f'  Scenario activator → HTTP {_act_resp.status_code} (all scenarios reactivated)')
                          healed += 1
                      else:
                          _act_msg = f'Make.com Scenario Activator returned HTTP {_act_resp.status_code}'
                          print(f'  WARNING: {_act_msg}')
                          unresolvable.append(_act_msg)
                  except Exception as _act_e:
                      print(f'  Scenario activator failed: {_act_e}')
              else:
                  # Fallback: just verify webhook URLs are configured (no HTTP call to poster webhooks)
                  _webhook_brands = {
                      'fitness': os.environ.get('MAKE_WEBHOOK_FITNESS', ''),
                      'deals': os.environ.get('MAKE_WEBHOOK_DEALS', ''),
                      'menopause': os.environ.get('MAKE_WEBHOOK_MENOPAUSE', ''),
                  }
                  for _wb_brand, _wb_url in _webhook_brands.items():
                      if _wb_url and _wb_url.startswith('https://hook.us2.make.com/'):
                          print(f'  {_wb_brand}: webhook configured ✓')
                          healed += 1
                      else:
                          _wb_msg = f'Make.com webhook for {_wb_brand} not configured'
                          print(f'  WARNING: {_wb_msg}')
                          unresolvable.append(_wb_msg)

              # ── Phase 8: Log self-healing activity ──
              try:
                  db.client.table('analytics').insert({
                      'event_type': 'self_healing',
                      'brand': 'system',
                      'platform': 'all',
                      'data': {
                          'issues_healed': healed,
                          'unresolvable_count': len(unresolvable),
                          'health_status': os.environ.get('HEALTH_STATUS', 'unknown'),
                          'timestamp': datetime.now(timezone.utc).isoformat()
                      }
                  }).execute()
              except Exception as e:
                  print(f'  Failed to log: {e}')

          # ── Check for truly unresolvable (critical-only) issues ──
          # ONLY flag issues that self-healing cannot fix:
          #   - API key invalid (401/403 after retry)
          #   - Supabase completely offline
          #   - All 3 Pinterest posting methods failed
          #   - Billing/payment issues
          # DO NOT flag transient issues (timeouts, rate limits, 429, 503, 504)
          try:
              health_issues = json.loads(os.environ.get('HEALTH_ISSUES', '[]'))
          except (json.JSONDecodeError, TypeError):
              raw = os.environ.get('HEALTH_ISSUES', '')
              health_issues = [raw] if raw and raw != '[]' else []

          transient_keywords = [
              'timeout', 'rate limit', 'temporarily', '429', '503', '504',
              'ECONNREFUSED', 'ECONNRESET', 'socket hang up', 'network error',
              'fetch failed', 'ETIMEDOUT', 'too many requests', 'connection refused',
          ]
          for issue in health_issues:
              il = issue.lower()
              # Skip transient issues — these self-heal
              if any(kw.lower() in il for kw in transient_keywords):
                  continue
              # Only unresolvable: API keys missing/invalid, billing, forbidden, Supabase offline
              if any(kw in il for kw in ['not configured', '401', '403', 'forbidden',
                                          'payment', 'billing', 'subscription',
                                          'supabase', 'all pinterest methods failed']):
                  unresolvable.append(issue)

          # ── Retry tracking: only notify after 10 consecutive failures ──
          # Store failure count in analytics table as a tracker
          RETRY_THRESHOLD = 10
          should_notify = False
          if unresolvable and db:
              try:
                  # Check existing retry counter
                  tracker = db.client.table('analytics').select('id, data') \
                      .eq('event_type', 'unresolvable_tracker') \
                      .eq('brand', 'system') \
                      .order('created_at', desc=True).limit(1).execute()

                  if tracker.data:
                      tracker_data = tracker.data[0].get('data', {})
                      if isinstance(tracker_data, str):
                          tracker_data = json.loads(tracker_data)
                      attempt = tracker_data.get('attempt', 0) + 1
                      prev_issues = set(tracker_data.get('issues', []))
                      curr_issues = set(unresolvable)

                      # Reset counter if the issues changed
                      if curr_issues != prev_issues:
                          attempt = 1

                      # Update tracker
                      db.client.table('analytics').update({
                          'data': {'attempt': attempt, 'issues': unresolvable, 'last_seen': datetime.now(timezone.utc).isoformat()}
                      }).eq('id', tracker.data[0]['id']).execute()

                      if attempt >= RETRY_THRESHOLD:
                          should_notify = True
                          print(f'  Attempt {attempt}/{RETRY_THRESHOLD} — NOTIFYING owner')
                          # Reset counter after notifying
                          db.client.table('analytics').update({
                              'data': {'attempt': 0, 'issues': unresolvable, 'notified_at': datetime.now(timezone.utc).isoformat()}
                          }).eq('id', tracker.data[0]['id']).execute()
                      else:
                          print(f'  Attempt {attempt}/{RETRY_THRESHOLD} — will keep trying before notifying')
                  else:
                      # First time seeing unresolvable issues — start counter at 1
                      db.client.table('analytics').insert({
                          'event_type': 'unresolvable_tracker',
                          'brand': 'system',
                          'platform': 'all',
                          'data': {'attempt': 1, 'issues': unresolvable, 'last_seen': datetime.now(timezone.utc).isoformat()}
                      }).execute()
                      print(f'  Attempt 1/{RETRY_THRESHOLD} — will keep trying before notifying')
              except Exception as e:
                  print(f'  Retry tracking failed: {e}')
                  # If tracking fails, notify to be safe
                  should_notify = True
          elif not unresolvable and db:
              # All clear — reset tracker if it exists
              try:
                  tracker = db.client.table('analytics').select('id') \
                      .eq('event_type', 'unresolvable_tracker') \
                      .eq('brand', 'system').limit(1).execute()
                  if tracker.data:
                      db.client.table('analytics').update({
                          'data': {'attempt': 0, 'issues': [], 'cleared_at': datetime.now(timezone.utc).isoformat()}
                      }).eq('id', tracker.data[0]['id']).execute()
              except:
                  pass

          # Write outputs — only flag for notification if threshold reached
          notify_count = len(unresolvable) if should_notify else 0
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f'unresolvable={notify_count}\n')
              f.write(f'unresolvable_details={json.dumps(unresolvable if should_notify else [])}\n')

          print(f'\n=== Self-Healing Summary ===')
          print(f'  Issues healed: {healed}')
          print(f'  Unresolvable: {len(unresolvable)}')
          print(f'  Will notify: {should_notify}')
          for u in unresolvable:
              print(f'    - {u}')
          PYEOF

  # Only email if self-healing found issues it truly cannot fix
  alert-unresolvable:
    runs-on: ubuntu-latest
    needs: [health-check, self-heal]
    if: needs.self-heal.outputs.unresolvable != '0' && needs.self-heal.outputs.unresolvable != ''
    timeout-minutes: 5

    steps:
      - name: Send alert for unresolvable issues only
        env:
          RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
          ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}
          UNRESOLVABLE_DETAILS: '${{ needs.self-heal.outputs.unresolvable_details }}'
        run: |
          pip install resend
          python3 << 'PYEOF'
          import os
          import json

          resend_key = os.environ.get('RESEND_API_KEY', '')
          alert_email = os.environ.get('ALERT_EMAIL', '')

          if not resend_key or not alert_email:
              print('Email not configured')
              exit(0)

          try:
              details = json.loads(os.environ.get('UNRESOLVABLE_DETAILS', '[]'))
          except (json.JSONDecodeError, TypeError):
              raw = os.environ.get('UNRESOLVABLE_DETAILS', '')
              details = [raw] if raw and raw != '[]' else []

          if not details:
              print('No unresolvable issues — no email needed')
              exit(0)

          import resend
          resend.api_key = resend_key

          issue_list = ''.join([f'<li style="margin:5px 0;padding:8px;background:#fef2f2;border-radius:4px;">{d}</li>' for d in details])

          html = f'''
          <div style="font-family:-apple-system,Arial,sans-serif;max-width:500px;margin:0 auto">
            <div style="background:#dc2626;color:white;padding:20px;text-align:center;border-radius:8px 8px 0 0">
              <h2 style="margin:0">Action Required</h2>
              <p style="margin:5px 0 0 0;opacity:0.9">Self-healing could not fix these issues</p>
            </div>
            <div style="padding:20px;border:1px solid #e5e7eb;border-top:none;border-radius:0 0 8px 8px">
              <ul style="list-style:none;padding:0;margin:0">{issue_list}</ul>
              <p style="color:#6b7280;font-size:13px;margin-top:15px">
                These require manual attention — check GitHub Secrets or API dashboards.
                Self-healing auto-resolved all other issues.
              </p>
            </div>
          </div>
          '''

          try:
              resend.Emails.send({
                  'from': 'alerts@socialmediaempire.com',
                  'to': [alert_email],
                  'subject': f'Action Required: {len(details)} issue(s) self-healing cannot fix',
                  'html': html
              })
              print(f'Alert sent for {len(details)} unresolvable issues')
          except Exception as e:
              print(f'Failed to send: {e}')
          PYEOF

      - name: Create GitHub summary
        if: always()
        run: |
          echo "## System Health" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ needs.health-check.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Unresolvable issues:** ${{ needs.self-heal.outputs.unresolvable }}" >> $GITHUB_STEP_SUMMARY
          echo "_Only unresolvable issues trigger email. Everything else is auto-healed._" >> $GITHUB_STEP_SUMMARY
