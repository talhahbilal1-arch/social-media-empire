name: Content Engine

on:
  schedule:
    # 5 runs per day — staggered for Pinterest optimal times (PST)
    - cron: '0 15 * * *'  # 7 AM PST
    - cron: '0 18 * * *'  # 10 AM PST
    - cron: '0 21 * * *'  # 1 PM PST
    - cron: '0 1 * * *'   # 5 PM PST (next day UTC)
    - cron: '0 4 * * *'   # 8 PM PST (next day UTC)
  workflow_dispatch:
    inputs:
      brand:
        description: 'Specific brand to generate for (fitness/deals/menopause)'
        required: false
        type: string
      dry_run:
        description: 'Dry run (no posting)'
        required: false
        type: boolean
        default: false

permissions:
  contents: write

env:
  PYTHON_VERSION: '3.11'

jobs:
  generate-and-post:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Pre-flight check
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          MAKE_WEBHOOK_FITNESS: ${{ secrets.MAKE_WEBHOOK_FITNESS }}
          MAKE_WEBHOOK_DEALS: ${{ secrets.MAKE_WEBHOOK_DEALS }}
          MAKE_WEBHOOK_MENOPAUSE: ${{ secrets.MAKE_WEBHOOK_MENOPAUSE }}
          MAKE_WEBHOOK_PINTEREST: ${{ secrets.MAKE_WEBHOOK_DEALS }}
        run: python3 scripts/preflight_check.py

      - name: Generate and post pins
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          CREATOMATE_API_KEY: ${{ secrets.CREATOMATE_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          MAKE_WEBHOOK_FITNESS: ${{ secrets.MAKE_WEBHOOK_FITNESS }}
          MAKE_WEBHOOK_DEALS: ${{ secrets.MAKE_WEBHOOK_DEALS }}
          MAKE_WEBHOOK_MENOPAUSE: ${{ secrets.MAKE_WEBHOOK_MENOPAUSE }}
          MAKE_WEBHOOK_PINTEREST: ${{ secrets.MAKE_WEBHOOK_DEALS }}
          DRY_RUN: ${{ github.event.inputs.dry_run || 'false' }}
        run: |
          python3 << 'PYEOF'
          import os
          import sys
          import json
          import requests
          import subprocess
          import time
          from datetime import datetime, timezone

          sys.path.insert(0, '.')
          from video_automation.content_brain import (
              generate_pin_content, generate_pin_from_calendar,
              generate_pin_from_daily_trend,
              log_pin_to_history, build_destination_url
          )
          from video_automation.image_selector import get_unique_pexels_image
          from video_automation.pin_image_generator import render_pin_to_bytes, map_visual_style
          from video_automation.supabase_storage import upload_pin_image
          from video_automation.pinterest_boards import get_board_id
          from video_automation.pin_article_generator import (
              generate_article_for_pin, article_to_html, save_and_register_article
          )

          dry_run = os.environ.get('DRY_RUN', 'false') == 'true'

          # Override brand if specified, else all 3 brands every run (1 pin each = 15/day)
          manual_brand = os.environ.get('BRAND', '${{ github.event.inputs.brand }}').strip()
          if manual_brand and manual_brand != '':
              brands = [b.strip() for b in manual_brand.split(',')]
          else:
              brands = ['fitness', 'deals', 'menopause']

          # Initialize Supabase
          from database.supabase_client import get_supabase_client
          db = get_supabase_client()

          def post_to_make_webhook(webhook_url, payload, brand_name, max_retries=2):
              """Post to Make.com webhook with retry logic."""
              for attempt in range(1, max_retries + 1):
                  try:
                      resp = requests.post(webhook_url, json=payload, timeout=30)
                      if resp.status_code < 400:
                          return True, f'{resp.status_code}'
                      error_msg = f'HTTP {resp.status_code}: {resp.text[:300]}'
                      print(f'  Make.com attempt {attempt}/{max_retries} failed for {brand_name}: {error_msg}')
                  except requests.exceptions.RequestException as req_err:
                      error_msg = str(req_err)
                      print(f'  Make.com attempt {attempt}/{max_retries} request error for {brand_name}: {error_msg}')

                  if attempt < max_retries:
                      print(f'  Waiting 60s before retry...')
                      time.sleep(60)

              return False, error_msg

          # ══════════════════════════════════════════════════════════════
          # PHASE 1: Generate all pin content (Claude calls)
          # ══════════════════════════════════════════════════════════════
          print('=== PHASE 1: Generating pin content ===')
          pin_data_by_brand = {}
          for brand in brands:
              brand = brand.strip()
              print(f'\n--- Generating content for {brand} ---')
              try:
                  # Count today's posts to determine run_index
                  today_date_str = datetime.now(timezone.utc).strftime('%Y-%m-%d')
                  try:
                      today_posts = db.client.table('content_history') \
                          .select('id') \
                          .eq('brand', brand) \
                          .gte('created_at', today_date_str + 'T00:00:00Z') \
                          .execute()
                      run_index = len(today_posts.data) if today_posts.data else 0
                  except Exception:
                      run_index = 0
                  print(f'  Run index: {run_index} (posts today so far)')

                  # 3-tier priority: daily trends → weekly calendar → random static topics
                  pin_data = generate_pin_from_daily_trend(brand, run_index, db.client)
                  if pin_data is not None:
                      print(f'  Source: DAILY TREND')
                  else:
                      pin_data = generate_pin_from_calendar(brand, db.client)
                      if pin_data is not None:
                          print(f'  Source: WEEKLY CALENDAR')
                      else:
                          print(f'  Calendar exhausted for today, using random topic')
                          pin_data = generate_pin_content(brand, db.client)
                          print(f'  Source: RANDOM STATIC')
                  print(f'  Title: {pin_data["title"]}')
                  print(f'  Board: {pin_data["board"]}')
                  print(f'  Style: {pin_data["visual_style"]}')
                  print(f'  Topic: {pin_data.get("topic", "N/A")}')
                  pin_data_by_brand[brand] = pin_data
              except Exception as e:
                  print(f'  ERROR generating content for {brand}: {e}')
                  import traceback
                  traceback.print_exc()
                  pin_data_by_brand[brand] = None

          # ══════════════════════════════════════════════════════════════
          # PHASE 2: Generate articles for each pin (Claude calls)
          # ══════════════════════════════════════════════════════════════
          print('\n=== PHASE 2: Generating articles ===')
          from video_automation.pin_article_generator import BRAND_SITE_CONFIG, _make_slug
          articles_generated = []
          for brand, pin_data in pin_data_by_brand.items():
              if pin_data is None:
                  continue
              print(f'\n--- Generating article for {brand} ---')
              try:
                  slug, article_md = generate_article_for_pin(brand, pin_data, db.client)
                  if slug and article_md:
                      html = article_to_html(article_md, brand, slug)
                      article_url = save_and_register_article(html, brand, slug, pin_data, db.client)
                      pin_data['destination_url'] = article_url
                      articles_generated.append(f'{brand}: {slug}')
                      print(f'  Article saved: {slug} -> {article_url}')
                  elif slug:
                      # Article already existed or generation skipped — still link to article URL
                      site = BRAND_SITE_CONFIG.get(brand, {})
                      base_url = site.get('base_url', pin_data.get('destination_url', ''))
                      pin_data['destination_url'] = f'{base_url}/articles/{slug}.html'
                      print(f'  Article already exists: {slug} -> {pin_data["destination_url"]}')
                  else:
                      print(f'  No topic for article, using homepage')
              except Exception as e:
                  print(f'  Article generation failed for {brand}: {e}')
                  import traceback
                  traceback.print_exc()
                  # Even if generation failed, try to construct article URL from topic
                  topic = pin_data.get('topic', '') or pin_data.get('trending_topic', '')
                  if topic:
                      fallback_slug = _make_slug(topic)
                      if fallback_slug:
                          site = BRAND_SITE_CONFIG.get(brand, {})
                          base_url = site.get('base_url', pin_data.get('destination_url', ''))
                          pin_data['destination_url'] = f'{base_url}/articles/{fallback_slug}.html'
                          print(f'  Fallback article URL: {pin_data["destination_url"]}')

          # ══════════════════════════════════════════════════════════════
          # PHASE 3: Git commit + push articles (before posting pins)
          # ══════════════════════════════════════════════════════════════
          if articles_generated and not dry_run:
              print('\n=== PHASE 3: Publishing articles ===')
              try:
                  subprocess.run(['git', 'config', 'user.name', 'Content Engine Bot'], check=True)
                  subprocess.run(['git', 'config', 'user.email', 'bot@fitover35.com'], check=True)
                  subprocess.run(['git', 'add', 'outputs/'], check=True)
                  result = subprocess.run(['git', 'diff', '--staged', '--quiet'])
                  if result.returncode != 0:
                      timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M')
                      subprocess.run(
                          ['git', 'commit', '-m', f'content: publish pin articles {timestamp}'],
                          check=True
                      )
                      subprocess.run(['git', 'push'], check=True)
                      print(f'  Pushed {len(articles_generated)} articles')
                      # Wait for deploy to propagate
                      print('  Waiting 30s for deploy...')
                      time.sleep(30)
                  else:
                      print('  No new article files to commit')
              except Exception as e:
                  print(f'  Git push failed: {e} — pins will link to homepage')
                  import traceback
                  traceback.print_exc()
          else:
              print('\n=== PHASE 3: Skipped (no articles or dry run) ===')

          # ══════════════════════════════════════════════════════════════
          # PHASE 4: Render images, upload, post via Make.com
          # ══════════════════════════════════════════════════════════════
          print('\n=== PHASE 4: Rendering and posting pins ===')
          results = []
          for brand_idx, brand in enumerate(brands):
              brand = brand.strip()
              pin_data = pin_data_by_brand.get(brand)
              if pin_data is None:
                  results.append({'brand': brand, 'status': 'failed', 'error': 'content generation failed'})
                  continue

              print(f'\n--- Posting pin for {brand} ---')
              try:
                  # Step 1: Get unique image from Pexels
                  image = get_unique_pexels_image(
                      pin_data['image_search_query'], brand, db.client
                  )
                  pin_data['pexels_image_id'] = image['id']
                  pin_data['image_url'] = image['url']
                  print(f'  Image: {image["id"]} by {image["photographer"]}')

                  # Step 2: Render text overlay pin with PIL (always numbered_list with 5 tips)
                  tips = pin_data.get('tips', [])
                  if tips and len(tips) >= 2:
                      # Format tips as numbered list for the renderer
                      tips_subheadline = ' '.join(f'{i+1}. {t}' for i, t in enumerate(tips[:5]))
                      pil_style = 'numbered_list'
                  else:
                      # Fallback if no tips generated
                      tips_subheadline = pin_data['title']
                      pil_style = map_visual_style(pin_data['visual_style'])
                  image_bytes = render_pin_to_bytes(
                      brand=brand,
                      headline=pin_data['title'],
                      subheadline=tips_subheadline,
                      keyword_or_url=image['url'],
                      style=pil_style,
                  )
                  print(f'  Rendered pin: {len(image_bytes)} bytes ({pil_style} style, {len(tips)} tips)')

                  # Step 3: Upload to Supabase Storage
                  timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')
                  filename = f'{brand}_{timestamp}.jpg'
                  rendered_url = upload_pin_image(image_bytes, filename)
                  print(f'  Uploaded: {rendered_url}')

                  # Step 4: Build destination URL with UTM
                  posting_method = f'make_{brand}'
                  topic_slug = pin_data.get('topic', '').replace(' ', '-').replace('/', '-')[:40]
                  pin_data['destination_url'] = build_destination_url(
                      pin_data['destination_url'], brand, posting_method, 'pins',
                      topic_slug=topic_slug, board_name=pin_data.get('board', '')
                  )

                  # Step 5: Resolve board_id from board name
                  board_id = get_board_id(brand, pin_data.get('board', ''))
                  print(f'  Board ID: {board_id}')

                  if dry_run:
                      print(f'  [DRY RUN] Would post: {pin_data["title"]}')
                      print(f'  [DRY RUN] Destination: {pin_data["destination_url"]}')
                      results.append({'brand': brand, 'status': 'dry_run', 'title': pin_data['title']})
                      continue

                  # Step 6: Post via Make.com webhook (per-brand routing with global fallback)
                  brand_map = {
                      'fitness': 'fitness-made-easy',
                      'deals': 'daily-deal-darling',
                      'menopause': 'menopause-planner',
                  }
                  webhook_keys = {
                      'fitness': 'MAKE_WEBHOOK_FITNESS',
                      'deals': 'MAKE_WEBHOOK_DEALS',
                      'menopause': 'MAKE_WEBHOOK_MENOPAUSE',
                  }
                  webhook = (
                      os.environ.get(webhook_keys.get(brand, ''), '')
                      or os.environ.get('MAKE_WEBHOOK_PINTEREST', '')
                  )
                  if webhook:
                      payload = {
                          'brand': brand_map.get(brand, brand),
                          'title': pin_data['title'],
                          'description': pin_data['description'],
                          'image_url': rendered_url,
                          'board_id': board_id,
                          'link': pin_data['destination_url'],
                      }
                      success, result_msg = post_to_make_webhook(webhook, payload, brand)
                      if success:
                          pin_data['posting_method'] = posting_method
                          print(f'  Posted via Make.com ({posting_method}): {result_msg}')
                      else:
                          print(f'  Make.com webhook FAILED after retries for {brand}: {result_msg}')
                          pin_data['posting_method'] = 'failed'
                  else:
                      print(f'  WARNING: No Make.com webhook configured - skipping {brand}')
                      pin_data['posting_method'] = 'skipped'

                  # Step 7: Log to content_history
                  status_map = {'skipped': 'skipped', 'failed': 'failed'}
                  actual_status = status_map.get(pin_data.get('posting_method', ''), 'posted')
                  log_pin_to_history(pin_data, db.client)
                  results.append({'brand': brand, 'status': actual_status, 'title': pin_data['title']})
                  print(f'  Status: {actual_status} | Logged to content_history')

                  # Stagger posts 30s apart between brands
                  if actual_status == 'posted' and brand_idx < len(brands) - 1:
                      print(f'  Waiting 30s before next brand...')
                      time.sleep(30)

              except Exception as e:
                  print(f'  ERROR generating/posting for {brand}: {e}')
                  import traceback
                  traceback.print_exc()
                  try:
                      db.client.table('errors').insert({
                          'error_type': 'content_engine',
                          'error_message': str(e),
                          'context': json.dumps({'brand': brand}),
                          'severity': 'high',
                          'created_at': datetime.now(timezone.utc).isoformat()
                      }).execute()
                  except:
                      pass
                  results.append({'brand': brand, 'status': 'failed', 'error': str(e)})
                  continue

          # Summary
          print(f'\n=== Content Engine Summary ===')
          for r in results:
              status = r['status'].upper()
              print(f'  {r["brand"]}: {status} - {r.get("title", r.get("error", ""))}')
          if articles_generated:
              print(f'\n  Articles published: {len(articles_generated)}')
              for a in articles_generated:
                  print(f'    {a}')

          # Update agent_runs
          posted = [r for r in results if r['status'] == 'posted']
          failed = [r for r in results if r['status'] == 'failed']
          skipped = [r for r in results if r['status'] == 'skipped']
          if skipped:
              print(f'\n  WARNING: {len(skipped)} brand(s) skipped due to missing config')
          if failed:
              print(f'  WARNING: {len(failed)} brand(s) failed to post')
          agents_to_update = ['content_brain', 'content_pipeline', 'image_selector']
          if posted:
              agents_to_update.append('multi_platform_poster')
          for agent in agents_to_update:
              try:
                  db.client.table('agent_runs').upsert({
                      'agent_name': agent,
                      'last_run_at': datetime.now(timezone.utc).isoformat(),
                      'status': 'success' if posted else 'failed',
                      'updated_at': datetime.now(timezone.utc).isoformat()
                  }, on_conflict='agent_name').execute()
              except:
                  pass

          # Fail the workflow only if ALL brands failed
          non_failed = [r for r in results if r['status'] != 'failed']
          if not non_failed:
              sys.exit(1)
          PYEOF

      - name: Deploy brand sites to Vercel
        if: '!cancelled()'
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_BRAND_TOKEN }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
          FITOVER35_PROJECT_ID: ${{ secrets.VERCEL_FITOVER35_PROJECT_ID }}
          DEALS_PROJECT_ID: ${{ secrets.VERCEL_DEALS_PROJECT_ID }}
          MENOPAUSE_PROJECT_ID: ${{ secrets.VERCEL_MENOPAUSE_PROJECT_ID }}
        run: |
          npm install -g vercel@latest
          echo "=== Deploying brand sites ==="

          if [ -n "$FITOVER35_PROJECT_ID" ]; then
            cd $GITHUB_WORKSPACE/outputs/fitover35-website
            VERCEL_PROJECT_ID="$FITOVER35_PROJECT_ID" vercel deploy --prod --yes --token $VERCEL_TOKEN . \
              && echo "✅ fitover35 deployed" || echo "❌ fitover35 deploy failed"
            cd $GITHUB_WORKSPACE
          else
            echo "⏭ fitover35: VERCEL_FITOVER35_PROJECT_ID not set, skipping"
          fi

          if [ -n "$DEALS_PROJECT_ID" ]; then
            cd $GITHUB_WORKSPACE/outputs/dailydealdarling-website
            VERCEL_PROJECT_ID="$DEALS_PROJECT_ID" vercel deploy --prod --yes --token $VERCEL_TOKEN . \
              && echo "✅ dailydealdarling deployed" || echo "❌ deals deploy failed"
            cd $GITHUB_WORKSPACE
          else
            echo "⏭ dailydealdarling: VERCEL_DEALS_PROJECT_ID not set, skipping"
          fi

          if [ -n "$MENOPAUSE_PROJECT_ID" ]; then
            cd $GITHUB_WORKSPACE/outputs/menopause-planner-website
            VERCEL_PROJECT_ID="$MENOPAUSE_PROJECT_ID" vercel deploy --prod --yes --token $VERCEL_TOKEN . \
              && echo "✅ menopause-planner deployed" || echo "❌ menopause deploy failed"
          else
            echo "⏭ menopause-planner: VERCEL_MENOPAUSE_PROJECT_ID not set, skipping"
          fi

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: content-engine-${{ github.run_number }}
          path: '*.log'
          retention-days: 7
