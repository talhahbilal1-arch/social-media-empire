name: Content Engine

on:
  schedule:
    # 3 runs per day â€” staggered for Pinterest optimal times
    - cron: '0 17 * * *'  # 9 AM PST (peak morning scroll)
    - cron: '0 21 * * *'  # 1 PM PST
    - cron: '0 4 * * *'   # 8 PM PST (peak evening scroll)
  workflow_dispatch:
    inputs:
      brand:
        description: 'Specific brand to generate for (fitness/deals/menopause)'
        required: false
        type: string
      dry_run:
        description: 'Dry run (no posting)'
        required: false
        type: boolean
        default: false

env:
  PYTHON_VERSION: '3.11'

jobs:
  generate-and-post:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Determine posting slot
        id: slot
        run: |
          # Determine which slot this is based on cron schedule
          HOUR=$(date -u +%H)
          if [ "$HOUR" -ge "16" ] && [ "$HOUR" -le "18" ]; then
            SLOT="morning"
            BRANDS="fitness,deals,menopause"
          elif [ "$HOUR" -ge "20" ] && [ "$HOUR" -le "22" ]; then
            SLOT="afternoon"
            BRANDS="fitness,deals"
          else
            SLOT="evening"
            BRANDS="fitness,menopause"
          fi

          # Override if manual brand specified
          if [ -n "${{ github.event.inputs.brand }}" ]; then
            BRANDS="${{ github.event.inputs.brand }}"
          fi

          echo "slot=$SLOT" >> $GITHUB_OUTPUT
          echo "brands=$BRANDS" >> $GITHUB_OUTPUT
          echo "Slot: $SLOT | Brands: $BRANDS"

      - name: Generate and post pins
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          CREATOMATE_API_KEY: ${{ secrets.CREATOMATE_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          LATE_API_KEY: ${{ secrets.LATE_API_KEY }}
          LATE_API_KEY_2: ${{ secrets.LATE_API_KEY_2 }}
          LATE_API_KEY_3: ${{ secrets.LATE_API_KEY_3 }}
          LATE_API_KEY_4: ${{ secrets.LATE_API_KEY_4 }}
          MAKE_WEBHOOK_DEALS: ${{ secrets.MAKE_WEBHOOK_DEALS }}
          MAKE_WEBHOOK_MENOPAUSE: ${{ secrets.MAKE_WEBHOOK_MENOPAUSE }}
          PINTEREST_FITNESS_ACCOUNT_ID: ${{ secrets.PINTEREST_FITNESS_ACCOUNT_ID }}
          PINTEREST_FITNESS_BOARD_ID: ${{ secrets.PINTEREST_FITNESS_BOARD_ID }}
          DRY_RUN: ${{ github.event.inputs.dry_run || 'false' }}
        run: |
          python -c "
          import os
          import sys
          import json
          import requests
          import time
          from datetime import datetime

          sys.path.insert(0, '.')
          from video_automation.content_brain import generate_pin_content, generate_pin_from_calendar, log_pin_to_history
          from video_automation.image_selector import get_unique_pexels_image

          dry_run = os.environ.get('DRY_RUN', 'false') == 'true'
          brands = os.environ.get('BRANDS', '${{ steps.slot.outputs.brands }}').split(',')
          slot = '${{ steps.slot.outputs.slot }}'

          # Initialize Supabase
          from database.supabase_client import get_supabase_client
          db = get_supabase_client()

          # Collect all available Late API keys for rotation (4 keys x 20 posts/month = 80/month)
          late_keys = []
          for key_name in ['LATE_API_KEY', 'LATE_API_KEY_2', 'LATE_API_KEY_3', 'LATE_API_KEY_4']:
              key_val = os.environ.get(key_name, '')
              if key_val:
                  late_keys.append((key_name, key_val))
          print(f'Available Late API keys: {len(late_keys)}')

          results = []
          for brand in brands:
              brand = brand.strip()
              print(f'\n=== Generating pin for {brand} ===')
              try:
                  # Step 1: Generate content via Claude (calendar-aware with fallback)
                  pin_data = generate_pin_from_calendar(brand, db.client)
                  if pin_data is None:
                      print(f'  Calendar exhausted for today, using random topic')
                      pin_data = generate_pin_content(brand, db.client)
                  print(f'  Title: {pin_data[\"title\"]}')
                  print(f'  Board: {pin_data[\"board\"]}')
                  print(f'  Style: {pin_data[\"visual_style\"]}')

                  # Step 2: Get unique image
                  image = get_unique_pexels_image(
                      pin_data['image_search_query'], brand, db.client
                  )
                  pin_data['pexels_image_id'] = image['id']
                  pin_data['image_url'] = image['url']
                  print(f'  Image: {image[\"id\"]} by {image[\"photographer\"]}')

                  # Step 3: Build destination URL with UTM
                  from video_automation.content_brain import build_destination_url
                  posting_method = 'late_api' if brand == 'fitness' else f'make_s{1 if brand == \"deals\" else 2}'
                  # Generate topic slug for pin-level UTM tracking
                  topic_slug = pin_data.get('topic', '').replace(' ', '-').replace('/', '-')[:40]
                  pin_data['destination_url'] = build_destination_url(
                      pin_data['destination_url'], brand, posting_method, slot,
                      topic_slug=topic_slug, board_name=pin_data.get('board', '')
                  )

                  if dry_run:
                      print(f'  [DRY RUN] Would post: {pin_data[\"title\"]}')
                      results.append({'brand': brand, 'status': 'dry_run', 'title': pin_data['title']})
                      continue

                  # Step 4: Post via appropriate method
                  if brand == 'fitness':
                      # Post via Late API with 4-key rotation
                      # Rotate primary key based on day of month to spread usage evenly
                      day = datetime.utcnow().day
                      if not late_keys:
                          raise Exception('No Late API keys configured')

                      # Order keys starting from the day-based primary
                      start_idx = day % len(late_keys)
                      ordered_keys = late_keys[start_idx:] + late_keys[:start_idx]

                      account_id = os.environ.get('PINTEREST_FITNESS_ACCOUNT_ID', '')
                      board_id = os.environ.get('PINTEREST_FITNESS_BOARD_ID', '')

                      post_success = False
                      last_error = ''
                      for key_name, late_key in ordered_keys:
                          print(f'  Trying {key_name} ({late_key[:8]}...)')

                          # Auto-detect account ID if not set (only need to do once)
                          if not account_id:
                              try:
                                  acct_resp = requests.get(
                                      'https://getlate.dev/api/v1/accounts',
                                      headers={'Authorization': f'Bearer {late_key}'},
                                      timeout=15
                                  )
                                  acct_resp.raise_for_status()
                                  accounts = acct_resp.json()
                                  if isinstance(accounts, dict):
                                      accounts = accounts.get('accounts', accounts.get('data', []))
                                  for acct in accounts:
                                      if acct.get('platform') == 'pinterest':
                                          account_id = acct.get('_id') or acct.get('id')
                                          break
                              except Exception as e:
                                  print(f'  Could not detect account with {key_name}: {e}')
                                  continue
                          if not account_id:
                              print(f'  No Pinterest account found, trying next key...')
                              continue

                          # Build payload per Late API docs (POST /posts)
                          content_text = f\"{pin_data['title']}\\n\\n{pin_data['description']}\"
                          platform_data = {
                              'platform': 'pinterest',
                              'accountId': account_id,
                              'platformSpecificData': {
                                  'link': pin_data['destination_url'],
                              }
                          }
                          if board_id:
                              platform_data['platformSpecificData']['boardId'] = board_id

                          post_payload = {
                              'content': content_text,
                              'platforms': [platform_data],
                              'mediaItems': [{'type': 'image', 'url': pin_data['image_url']}],
                          }

                          try:
                              post_resp = requests.post(
                                  'https://getlate.dev/api/v1/posts',
                                  headers={'Authorization': f'Bearer {late_key}', 'Content-Type': 'application/json'},
                                  json=post_payload,
                                  timeout=30
                              )
                              if post_resp.status_code == 403 and 'limit' in post_resp.text.lower():
                                  print(f'  {key_name} hit rate limit, trying next key...')
                                  last_error = f'{key_name} rate limited'
                                  continue
                              if post_resp.status_code >= 400:
                                  print(f'  {key_name} error {post_resp.status_code}: {post_resp.text[:300]}')
                                  last_error = f'{key_name} error {post_resp.status_code}'
                                  continue
                              post_result = post_resp.json()
                              post_obj = post_result.get('post', post_result)
                              pin_data['posting_method'] = 'late_api'
                              pin_data['late_post_id'] = post_obj.get('_id', '')
                              print(f'  Posted via Late API ({key_name}): {post_resp.status_code} | Post ID: {post_obj.get(\"_id\", \"unknown\")}')
                              post_success = True
                              break
                          except requests.exceptions.RequestException as e:
                              print(f'  {key_name} request failed: {e}')
                              last_error = str(e)
                              continue

                      if not post_success:
                          raise Exception(f'All Late API keys exhausted: {last_error}')

                  elif brand in ('deals', 'menopause'):
                      # Post via Make.com webhook (routes to correct Pinterest account)
                      webhook_var = 'MAKE_WEBHOOK_DEALS' if brand == 'deals' else 'MAKE_WEBHOOK_MENOPAUSE'
                      webhook = os.environ.get(webhook_var, '')
                      if webhook:
                          # Payload format matches Make.com 'Video to Pinterest - All Brands' scenario
                          brand_map = {'deals': 'daily-deal-darling', 'menopause': 'menopause-planner'}
                          payload = {
                              'brand': brand_map.get(brand, brand),
                              'title': pin_data['title'],
                              'description': pin_data['description'],
                              'video_url': pin_data['image_url'],
                              'link': pin_data['destination_url'],
                          }
                          resp = requests.post(webhook, json=payload, timeout=30)
                          if resp.status_code >= 400:
                              print(f'  Make.com webhook error {resp.status_code}: {resp.text[:300]}')
                              resp.raise_for_status()
                          method_name = 'make_s1' if brand == 'deals' else 'make_s2'
                          pin_data['posting_method'] = method_name
                          print(f'  Posted via Make.com ({method_name}): {resp.status_code}')
                      else:
                          print(f'  WARNING: {webhook_var} not configured - skipping {brand}')
                          pin_data['posting_method'] = 'skipped'

                  # Step 5: Log to content_history and track result correctly
                  actual_status = 'skipped' if pin_data.get('posting_method') == 'skipped' else 'posted'
                  log_pin_to_history(pin_data, db.client)
                  results.append({'brand': brand, 'status': actual_status, 'title': pin_data['title']})
                  print(f'  Status: {actual_status} | Logged to content_history')

                  # Stagger posts 5 minutes apart to avoid feed flooding (only for actual posts)
                  if actual_status == 'posted' and brand != brands[-1].strip():
                      print(f'  Waiting 5 minutes before next brand...')
                      time.sleep(300)

              except Exception as e:
                  print(f'  ERROR generating/posting for {brand}: {e}')
                  # Log error to Supabase
                  try:
                      db.client.table('errors').insert({
                          'error_type': 'content_engine',
                          'error_message': str(e),
                          'context': json.dumps({'brand': brand, 'slot': slot}),
                          'severity': 'high',
                          'created_at': datetime.utcnow().isoformat()
                      }).execute()
                  except:
                      pass
                  results.append({'brand': brand, 'status': 'failed', 'error': str(e)})
                  continue  # Don't let one failure kill the whole run

          # Summary
          print(f'\n=== Content Engine Summary ===')
          for r in results:
              status = r['status'].upper()
              print(f'  {r[\"brand\"]}: {status} - {r.get(\"title\", r.get(\"error\", \"\"))}')

          # Update agent_runs so monitoring knows we're alive
          posted = [r for r in results if r['status'] == 'posted']
          skipped = [r for r in results if r['status'] == 'skipped']
          if skipped:
              print(f'\n  WARNING: {len(skipped)} brand(s) skipped due to missing config')
          agents_to_update = ['content_brain', 'content_pipeline', 'image_selector']
          if posted:
              agents_to_update.append('multi_platform_poster')
          for agent in agents_to_update:
              try:
                  db.client.table('agent_runs').upsert({
                      'agent_name': agent,
                      'last_run_at': datetime.utcnow().isoformat(),
                      'status': 'success' if posted else 'failed',
                      'updated_at': datetime.utcnow().isoformat()
                  }, on_conflict='agent_name').execute()
              except:
                  pass  # Table may not exist yet

          # Fail the workflow only if ALL brands failed (skipped counts as non-failure)
          non_failed = [r for r in results if r['status'] != 'failed']
          if not non_failed:
              sys.exit(1)
          "

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: content-engine-${{ steps.slot.outputs.slot }}-${{ github.run_number }}
          path: '*.log'
          retention-days: 7
