name: Content Engine

on:
  schedule:
    # 3 runs per day — renders content_ready pins after Make.com content generator fills them
    - cron: '0 16 * * *'  # 8 AM PST
    - cron: '0 22 * * *'  # 2 PM PST
    - cron: '0 4 * * *'   # 8 PM PST (next day UTC)
  workflow_dispatch:
    inputs:
      brand:
        description: 'Specific brand to generate for (fitness/deals/menopause)'
        required: false
        type: string
      dry_run:
        description: 'Dry run (no posting)'
        required: false
        type: boolean
        default: false

permissions:
  contents: write

env:
  PYTHON_VERSION: '3.11'

jobs:
  generate-and-post:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Pre-flight check
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          MAKE_WEBHOOK_FITNESS: ${{ secrets.MAKE_WEBHOOK_FITNESS }}
          MAKE_WEBHOOK_DEALS: ${{ secrets.MAKE_WEBHOOK_DEALS }}
          MAKE_WEBHOOK_MENOPAUSE: ${{ secrets.MAKE_WEBHOOK_MENOPAUSE }}
          MAKE_WEBHOOK_PINTEREST: ${{ secrets.MAKE_WEBHOOK_FITNESS }}
        run: python3 scripts/preflight_check.py

      - name: Render and publish pins
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          PEXELS_API_KEY: ${{ secrets.PEXELS_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          MAKE_WEBHOOK_FITNESS: ${{ secrets.MAKE_WEBHOOK_FITNESS }}
          MAKE_WEBHOOK_DEALS: ${{ secrets.MAKE_WEBHOOK_DEALS }}
          MAKE_WEBHOOK_MENOPAUSE: ${{ secrets.MAKE_WEBHOOK_MENOPAUSE }}
          MAKE_WEBHOOK_ACTIVATOR: ${{ secrets.MAKE_WEBHOOK_ACTIVATOR }}
          DRY_RUN: ${{ github.event.inputs.dry_run || 'false' }}
          BRAND_INPUT: ${{ github.event.inputs.brand || '' }}
        run: |
          python3 << 'PYEOF'
          import os
          import sys
          import json
          import time
          import subprocess
          import urllib.request
          import urllib.error
          from datetime import datetime, timezone, timedelta
          from concurrent.futures import ThreadPoolExecutor

          sys.path.insert(0, '.')
          from video_automation.image_selector import get_unique_pexels_image
          from video_automation.pin_image_generator import render_pin_to_bytes
          from video_automation.supabase_storage import upload_pin_image
          from video_automation.pin_article_generator import (
              generate_article_for_pin, article_to_html, save_and_register_article,
              BRAND_SITE_CONFIG, _make_slug
          )
          from video_automation.content_brain import generate_pin_content, log_pin_to_history
          from video_automation.pinterest_boards import get_board_id

          dry_run = os.environ.get('DRY_RUN', 'false') == 'true'

          from database.supabase_client import get_supabase_client
          db = get_supabase_client()

          def log_pipeline_error(phase, brand, error, severity='medium'):
              """Log pipeline errors to Supabase errors table for system-health tracking."""
              try:
                  import traceback as _tb
                  db.client.table('errors').insert({
                      'error_type': 'content_engine',
                      'error_message': str(error)[:500],
                      'context': json.dumps({'phase': phase, 'brand': brand, 'trace': _tb.format_exc()[-500:]}),
                      'severity': severity,
                      'created_at': datetime.now(timezone.utc).isoformat()
                  }).execute()
              except Exception:
                  pass  # Never let error logging crash the pipeline

          # ══════════════════════════════════════════════════════════════
          # PRE-FLIGHT: Reactivate Make.com poster scenarios via Scenario
          # Activator webhook (bypasses Cloudflare that blocks direct API).
          # ══════════════════════════════════════════════════════════════
          activator_url = os.environ.get('MAKE_WEBHOOK_ACTIVATOR', '')
          if activator_url and not dry_run:
              print('=== PRE-FLIGHT: Reactivating Make.com scenarios ===')
              try:
                  _req = urllib.request.Request(
                      activator_url,
                      data=json.dumps({'action': 'activate_all'}).encode(),
                      headers={'Content-Type': 'application/json'},
                      method='POST'
                  )
                  with urllib.request.urlopen(_req, timeout=15) as _r:
                      print(f'  Scenario activator → HTTP {_r.status}')
                  time.sleep(5)  # Give scenarios time to activate before posting
              except Exception as _e:
                  print(f'  Scenario activator skipped: {_e}')

          # ══════════════════════════════════════════════════════════════
          # PHASE 0: Generate fresh pin content → insert as content_ready
          # ══════════════════════════════════════════════════════════════
          print('=== PHASE 0: Generating pin content ===')
          ALL_BRANDS = ['fitness', 'deals', 'menopause']
          brand_filter = os.environ.get('BRAND_INPUT', '').strip()
          brands_to_generate = [brand_filter] if brand_filter in ALL_BRANDS else ALL_BRANDS

          for brand in brands_to_generate:
              try:
                  print(f'  Generating content for {brand}...')
                  pin_data = generate_pin_content(brand, db.client)
                  board_id = get_board_id(brand, pin_data.get('board', ''))
                  tips = pin_data.get('tips', [])
                  insert_row = {
                      'brand': brand,
                      'title': pin_data.get('title', ''),
                      'description': pin_data.get('description', ''),
                      'overlay_headline': pin_data.get('graphic_title', pin_data.get('title', ''))[:60],
                      'overlay_subtext': tips[0] if tips else '',
                      'tips': tips,
                      'pexels_search_term': pin_data.get('image_search_query', ''),
                      'board_id': board_id,
                      'destination_url': pin_data.get('destination_url', ''),
                      'topic': pin_data.get('topic', ''),
                      'niche': pin_data.get('category', ''),
                      'status': 'content_ready',
                  }
                  if not dry_run:
                      db.client.table('pinterest_pins').insert(insert_row).execute()
                      log_pin_to_history(pin_data, db.client)
                  print(f'  [{brand}] Content ready: {pin_data.get("title", "")[:50]}')
              except Exception as e:
                  print(f'  ERROR generating content for {brand}: {e}')
                  import traceback; traceback.print_exc()
                  log_pipeline_error('0', brand, e, severity='high')
          print()

          # ══════════════════════════════════════════════════════════════
          # PHASE 1: Render content_ready pins → upload images → set ready
          # ══════════════════════════════════════════════════════════════
          print('=== PHASE 1: Rendering content_ready pins ===')
          cutoff = (datetime.now(timezone.utc) - timedelta(hours=24)).isoformat()
          try:
              query_result = db.client.table('pinterest_pins') \
                  .select('*') \
                  .eq('status', 'content_ready') \
                  .gte('created_at', cutoff) \
                  .execute()
              content_ready_pins = query_result.data or []
          except Exception as e:
              print(f'  WARNING: Could not query content_ready pins: {e}')
              log_pipeline_error('1', 'all', e, severity='high')
              content_ready_pins = []

          print(f'  Found {len(content_ready_pins)} content_ready pins')
          rendered_pins = []

          for pin in content_ready_pins:
              pin_id = pin['id']
              brand = pin['brand']
              try:
                  db.client.table('pinterest_pins').update({'status': 'rendering'}).eq('id', pin_id).execute()
              except Exception:
                  pass
              try:
                  search_term = pin.get('pexels_search_term') or pin.get('title', 'lifestyle photo')
                  image = get_unique_pexels_image(search_term, brand, db.client)

                  headline = pin.get('overlay_headline') or pin.get('title', '')
                  subheadline = pin.get('overlay_subtext') or ''

                  image_bytes = render_pin_to_bytes(
                      brand=brand,
                      headline=headline,
                      subheadline=subheadline,
                      keyword_or_url=image['url'],
                      style='gradient',
                  )

                  timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')
                  filename = f"{brand}_{pin_id}_{timestamp}.jpg"
                  image_url = upload_pin_image(image_bytes, filename)

                  db.client.table('pinterest_pins').update({
                      'image_url': image_url,
                      'generated_image_url': image_url,
                      'status': 'ready'
                  }).eq('id', pin_id).execute()

                  pin['image_url'] = image_url
                  rendered_pins.append(pin)
                  print(f'  [{brand}] Rendered: {pin.get("title", "")[:50]}')

              except Exception as e:
                  print(f'  ERROR rendering pin {pin_id} ({brand}): {e}')
                  import traceback; traceback.print_exc()
                  log_pipeline_error('1', brand, e, severity='medium')
                  try:
                      db.client.table('pinterest_pins').update({'status': 'content_ready'}).eq('id', pin_id).execute()
                  except Exception:
                      pass

          print(f'  Rendered {len(rendered_pins)}/{len(content_ready_pins)} pins')

          # ══════════════════════════════════════════════════════════════
          # PHASE 2: Generate articles FIRST so pins link to articles
          # (articles must exist before posting so "Visit Site" → article)
          # ══════════════════════════════════════════════════════════════
          print('\n=== PHASE 2: Generating articles ===')
          articles_generated = []
          _articles_lock = __import__('threading').Lock()

          def _generate_article_for_pin(pin):
              brand = pin['brand']
              print(f'\n  --- Article for {brand}: {pin.get("title", "")[:50]} ---')
              try:
                  pin_data = {
                      'title': pin.get('title', ''),
                      'description': pin.get('description', ''),
                      'topic': pin.get('topic', '') or pin.get('niche', ''),
                      'trending_topic': pin.get('topic', ''),
                      'destination_url': pin.get('destination_url', ''),
                      'image_url': pin.get('image_url', ''),
                      'board': pin.get('board_id', ''),
                      'pexels_search_term': pin.get('pexels_search_term', '') or pin.get('title', ''),
                      'tips': pin.get('tips_list', []) or [],
                      'category': pin.get('category', ''),
                  }
                  slug, article_md = generate_article_for_pin(brand, pin_data, db.client)
                  if slug and article_md:
                      html = article_to_html(article_md, brand, slug, pin_data)
                      article_url = save_and_register_article(html, brand, slug, pin_data, db.client)
                      # Update in-memory pin so Phase 1b uses the article URL as the "Visit Site" link
                      pin['destination_url'] = article_url
                      try:
                          db.client.table('pinterest_pins').update({
                              'destination_url': article_url,
                              'article_generated': True
                          }).eq('id', pin['id']).execute()
                      except Exception:
                          pass
                      with _articles_lock:
                          articles_generated.append(f'{brand}: {slug}')
                      print(f'  [{brand}] Article → {article_url}')
                  elif slug:
                      site = BRAND_SITE_CONFIG.get(brand, {})
                      base_url = site.get('base_url', pin_data.get('destination_url', ''))
                      article_url = f'{base_url}/articles/{slug}.html'
                      pin['destination_url'] = article_url  # Update in-memory
                      try:
                          db.client.table('pinterest_pins').update({
                              'destination_url': article_url,
                              'article_generated': True
                          }).eq('id', pin['id']).execute()
                      except Exception:
                          pass
                      print(f'  [{brand}] Article exists: {article_url}')
                  else:
                      print(f'  [{brand}] No topic — pin will link to homepage')
              except Exception as e:
                  print(f'  Article failed for {brand}: {e}')
                  import traceback; traceback.print_exc()
                  log_pipeline_error('2', brand, e, severity='medium')

          if rendered_pins:
              with ThreadPoolExecutor(max_workers=3) as executor:
                  list(executor.map(_generate_article_for_pin, rendered_pins))
          else:
              print('  No rendered pins — skipping article generation')

          # ══════════════════════════════════════════════════════════════
          # PHASE 3: Git commit + push articles (deploy before posting)
          # Vercel auto-deploys on push so articles are live before pins.
          # ══════════════════════════════════════════════════════════════
          if articles_generated and not dry_run:
              print('\n=== PHASE 3: Publishing articles ===')
              try:
                  subprocess.run(['git', 'config', 'user.name', 'Content Engine Bot'], check=True)
                  subprocess.run(['git', 'config', 'user.email', 'bot@fitover35.com'], check=True)
                  subprocess.run(['git', 'add', 'outputs/'], check=True)
                  result = subprocess.run(['git', 'diff', '--staged', '--quiet'])
                  if result.returncode != 0:
                      timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M')
                      subprocess.run(
                          ['git', 'commit', '-m', f'content: publish pin articles {timestamp}'],
                          check=True
                      )
                      subprocess.run(['git', 'push'], check=True)
                      print(f'  Pushed {len(articles_generated)} articles — Vercel deploying...')
                      time.sleep(20)  # Allow Vercel to start deploying before posting pins
                  else:
                      print('  No new article files to commit')
              except Exception as e:
                  print(f'  Git push failed: {e}')
                  import traceback; traceback.print_exc()
                  log_pipeline_error('3', 'all', e, severity='high')
          else:
              print('\n=== PHASE 3: Skipped ===')

          # ══════════════════════════════════════════════════════════════
          # PHASE 1b: Post rendered pins to Pinterest via Make.com webhooks
          # Runs AFTER articles are generated and pushed — so "Visit Site"
          # links directly to the conversion article, not the homepage.
          # Scenarios stay active via builtin:Ignore error handler.
          # ══════════════════════════════════════════════════════════════
          WEBHOOKS = {
              'fitness': os.environ.get('MAKE_WEBHOOK_FITNESS', ''),
              'deals': os.environ.get('MAKE_WEBHOOK_DEALS', ''),
              'menopause': os.environ.get('MAKE_WEBHOOK_MENOPAUSE', ''),
          }

          print('\n=== PHASE 1b: Posting pins to Pinterest ===')
          posted_count = 0
          for pin in rendered_pins:
              pin_id = pin['id']
              brand = pin['brand']
              webhook_url = WEBHOOKS.get(brand, '')
              if not webhook_url:
                  print(f'  [{brand}] SKIP — no webhook URL configured')
                  continue
              if dry_run:
                  print(f'  [{brand}] DRY RUN — would POST to article: {pin.get("destination_url","")[:70]}')
                  continue

              # CRITICAL: validate image_url — empty URL causes Pinterest 400
              image_url = pin.get('image_url', '') or ''
              if not image_url.startswith('http'):
                  print(f'  [{brand}] SKIP — image_url missing or invalid: "{image_url}"')
                  try:
                      db.client.table('pinterest_pins').update({
                          'status': 'failed',
                          'error_message': f'image_url missing: "{image_url}"',
                      }).eq('id', pin_id).execute()
                  except Exception:
                      pass
                  log_pipeline_error('1b', brand, f'image_url missing for pin {pin_id}', severity='high')
                  continue

              destination_url = pin.get('destination_url', '')
              payload = {
                  'pin_id': str(pin_id),
                  'brand': brand,
                  'title': pin.get('title', '')[:100],
                  'description': pin.get('description', '')[:500],
                  'image_url': image_url,
                  'link': destination_url,
                  'board_id': str(pin.get('board_id', '')),
              }
              print(f'  [{brand}] Posting → {destination_url[:70]}')
              print(f'  [{brand}]   board_id={payload["board_id"]}')

              # Retry logic: 3 attempts with exponential backoff
              success = False
              for attempt in range(3):
                  try:
                      if attempt == 0:
                          db.client.table('pinterest_pins').update({'status': 'posting'}).eq('id', pin_id).execute()
                      body = json.dumps(payload).encode('utf-8')
                      req = urllib.request.Request(
                          webhook_url,
                          data=body,
                          headers={'Content-Type': 'application/json'},
                          method='POST'
                      )
                      with urllib.request.urlopen(req, timeout=30) as resp:
                          resp_body = resp.read().decode('utf-8', errors='replace')
                          print(f'  [{brand}] Webhook → HTTP {resp.status} "{resp_body[:60]}"')
                      db.client.table('pinterest_pins').update({
                          'status': 'posted',
                          'posted_at': datetime.now(timezone.utc).isoformat()
                      }).eq('id', pin_id).execute()
                      posted_count += 1
                      success = True
                      break
                  except urllib.error.HTTPError as e:
                      err_body = e.read().decode('utf-8', errors='replace')[:200]
                      print(f'  [{brand}] Attempt {attempt+1}/3 FAILED — HTTP {e.code}: {err_body}')
                      if attempt < 2:
                          time.sleep(5 * (attempt + 1))
                      else:
                          try:
                              db.client.table('pinterest_pins').update({
                                  'status': 'failed',
                                  'error_message': f'Webhook HTTP {e.code}: {err_body}',
                              }).eq('id', pin_id).execute()
                          except Exception:
                              pass
                          log_pipeline_error('1b', brand, f'Webhook HTTP {e.code}: {err_body}', severity='high')
                  except Exception as e:
                      print(f'  [{brand}] Attempt {attempt+1}/3 FAILED — {e}')
                      if attempt < 2:
                          time.sleep(5 * (attempt + 1))
                      else:
                          try:
                              db.client.table('pinterest_pins').update({
                                  'status': 'failed',
                                  'error_message': str(e)[:200],
                              }).eq('id', pin_id).execute()
                          except Exception:
                              pass
                          log_pipeline_error('1b', brand, e, severity='high')

          print(f'  Posted {posted_count}/{len(rendered_pins)} pins to Pinterest')

          # ══════════════════════════════════════════════════════════════
          # PHASE 4: Verify results — log any lingering failures
          # ══════════════════════════════════════════════════════════════
          if not dry_run and rendered_pins:
              print('\n=== PHASE 4: Verification ===')
              try:
                  fresh_cutoff = (datetime.now(timezone.utc) - timedelta(minutes=30)).isoformat()
                  failed_pins = db.client.table('pinterest_pins').select('id,brand,error_message') \
                      .eq('status', 'failed').gte('created_at', fresh_cutoff).execute()
                  if failed_pins.data:
                      for fp in failed_pins.data:
                          print(f'  [{fp["brand"]}] FAILED pin {fp["id"]}: {fp.get("error_message","")[:80]}')
                  else:
                      print(f'  All pins posted successfully ({posted_count}/{len(rendered_pins)})')
              except Exception as e:
                  print(f'  Verification query failed: {e}')

          # Summary
          print(f'\n=== Content Engine Summary ===')
          print(f'  Rendered: {len(rendered_pins)} pins')
          print(f'  Articles: {len(articles_generated)}')
          print(f'  Posted: {posted_count} pins')
          if not content_ready_pins:
              print('  No content_ready pins — pipeline idle')
          try:
              db.client.table('agent_runs').upsert({
                  'agent_name': 'content_pipeline',
                  'last_run_at': datetime.now(timezone.utc).isoformat(),
                  'status': 'success' if rendered_pins else 'idle',
                  'updated_at': datetime.now(timezone.utc).isoformat()
              }, on_conflict='agent_name').execute()
          except Exception:
              pass
          PYEOF

      - name: Deploy brand sites to Vercel
        if: '!cancelled()'
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_BRAND_TOKEN }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
          FITOVER35_PROJECT_ID: ${{ secrets.VERCEL_FITOVER35_PROJECT_ID }}
          DEALS_PROJECT_ID: ${{ secrets.VERCEL_DEALS_PROJECT_ID }}
          MENOPAUSE_PROJECT_ID: ${{ secrets.VERCEL_MENOPAUSE_PROJECT_ID }}
        run: |
          npm install -g vercel@latest
          echo "=== Deploying brand sites in parallel ==="

          if [ -n "$FITOVER35_PROJECT_ID" ]; then
            cd $GITHUB_WORKSPACE/outputs/fitover35-website
            VERCEL_PROJECT_ID="$FITOVER35_PROJECT_ID" vercel deploy --prod --yes --token $VERCEL_TOKEN . \
              > /tmp/vercel_fitness.log 2>&1 && echo "✅ fitover35 deployed" >> /tmp/vercel_fitness.log \
              || echo "❌ fitover35 deploy failed" >> /tmp/vercel_fitness.log &
            cd $GITHUB_WORKSPACE
          else
            echo "⏭ fitover35: VERCEL_FITOVER35_PROJECT_ID not set, skipping"
          fi

          if [ -n "$DEALS_PROJECT_ID" ]; then
            cd $GITHUB_WORKSPACE/outputs/dailydealdarling-website
            VERCEL_PROJECT_ID="$DEALS_PROJECT_ID" vercel deploy --prod --yes --token $VERCEL_TOKEN . \
              > /tmp/vercel_deals.log 2>&1 && echo "✅ dailydealdarling deployed" >> /tmp/vercel_deals.log \
              || echo "❌ deals deploy failed" >> /tmp/vercel_deals.log &
            cd $GITHUB_WORKSPACE
          else
            echo "⏭ dailydealdarling: VERCEL_DEALS_PROJECT_ID not set, skipping"
          fi

          if [ -n "$MENOPAUSE_PROJECT_ID" ]; then
            cd $GITHUB_WORKSPACE/outputs/menopause-planner-website
            VERCEL_PROJECT_ID="$MENOPAUSE_PROJECT_ID" vercel deploy --prod --yes --token $VERCEL_TOKEN . \
              > /tmp/vercel_menopause.log 2>&1 && echo "✅ menopause-planner deployed" >> /tmp/vercel_menopause.log \
              || echo "❌ menopause deploy failed" >> /tmp/vercel_menopause.log &
            cd $GITHUB_WORKSPACE
          else
            echo "⏭ menopause-planner: VERCEL_MENOPAUSE_PROJECT_ID not set, skipping"
          fi

          echo "Waiting for parallel deploys to complete..."
          wait
          echo "=== Deploy logs ==="
          cat /tmp/vercel_*.log 2>/dev/null || true

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: content-engine-${{ github.run_number }}
          path: '*.log'
          retention-days: 7
