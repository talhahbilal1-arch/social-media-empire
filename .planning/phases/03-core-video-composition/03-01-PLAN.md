---
phase: 03-core-video-composition
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/video/__init__.py
  - src/video/compositor.py
autonomous: true

must_haves:
  truths:
    - "16:9 stock video is center-cropped to 9:16 without black bars"
    - "Output dimensions are exactly 1080x1920 pixels"
    - "Clips are tracked for memory cleanup"
  artifacts:
    - path: "src/video/__init__.py"
      provides: "Video module initialization"
    - path: "src/video/compositor.py"
      provides: "VideoCompositor class with convert_to_vertical method"
      exports: ["VideoCompositor"]
      min_lines: 60
  key_links:
    - from: "src/video/compositor.py"
      to: "moviepy"
      via: "VideoFileClip import"
      pattern: "from moviepy import VideoFileClip"
---

<objective>
Create the VideoCompositor class foundation with aspect ratio conversion from 16:9 to 9:16 vertical format.

Purpose: This is the core of the video composition engine. The aspect ratio converter transforms landscape stock footage into vertical social media format (1080x1920) by center-cropping, which is the most critical geometric transformation in the pipeline.

Output: `src/video/compositor.py` with `VideoCompositor` class containing `convert_to_vertical()` method and clip tracking for memory management.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-core-video-composition/03-RESEARCH.md
@src/models/brand.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create video module and VideoCompositor class skeleton</name>
  <files>src/video/__init__.py, src/video/compositor.py</files>
  <action>
Create the video module directory and initialize it:

1. Create `src/video/__init__.py` with exports:
   - Import and re-export VideoCompositor from compositor module

2. Create `src/video/compositor.py` with:
   - VideoCompositor class with `__init__` accepting `brand_config: BrandConfig`
   - Store `self.clips_to_close: list` for memory management
   - Add constants at module level:
     - `VIDEO_WIDTH = 1080`
     - `VIDEO_HEIGHT = 1920`
     - `SAFE_ZONE_MARGIN = 120`
     - `TARGET_FPS = 24`
   - Import from moviepy using 2.x syntax: `from moviepy import VideoFileClip`
   - Import BrandConfig from `src.models.brand`

Use MoviePy 2.0 import syntax (NOT moviepy.editor - that's deprecated).
  </action>
  <verify>
```bash
python -c "from src.video import VideoCompositor; print('Import OK')"
```
  </verify>
  <done>VideoCompositor class exists and is importable with brand_config parameter</done>
</task>

<task type="auto">
  <name>Task 2: Implement convert_to_vertical method</name>
  <files>src/video/compositor.py</files>
  <action>
Add the `convert_to_vertical` method to VideoCompositor class:

```python
def convert_to_vertical(self, video_path: str) -> VideoFileClip:
    """Convert 16:9 video to 9:16 by center cropping.

    Args:
        video_path: Path to input video file

    Returns:
        VideoFileClip resized to 1080x1920 (9:16)
    """
```

Implementation (from research Pattern 1):
1. Load video with `VideoFileClip(video_path)` and track in `self.clips_to_close`
2. Calculate target aspect ratio: `target_aspect = VIDEO_WIDTH / VIDEO_HEIGHT` (0.5625)
3. Get current aspect: `current_aspect = clip.w / clip.h`
4. If current_aspect > target_aspect (video is wider - most common for 16:9):
   - Calculate new_width = int(clip.h * target_aspect)
   - Calculate x1 = int((clip.w - new_width) / 2) for center crop
   - Crop with `clip.crop(x1=x1, y1=0, width=new_width, height=clip.h)`
5. Else (video is taller):
   - Calculate new_height = int(clip.w / target_aspect)
   - Calculate y1 = int((clip.h - new_height) / 2)
   - Crop with `clip.crop(x1=0, y1=y1, width=clip.w, height=new_height)`
6. Resize to exact dimensions: `cropped.resize((VIDEO_WIDTH, VIDEO_HEIGHT))`
7. Track cropped and resized clips in self.clips_to_close
8. Assert even dimensions: `assert final.w % 2 == 0 and final.h % 2 == 0`
9. Set FPS: `final = final.with_fps(TARGET_FPS)`
10. Return final clip

CRITICAL: Track all intermediate clips in self.clips_to_close for proper memory cleanup.
  </action>
  <verify>
Create a quick test script and run:
```bash
python -c "
from src.video import VideoCompositor
from src.models.brand import BrandConfig, ColorPalette
from pydantic_extra_types.color import Color

# Create minimal brand config for testing
brand = BrandConfig(
    name='Test',
    slug='test',
    colors=ColorPalette(primary=Color('#000000'), secondary=Color('#FFFFFF')),
    tts_voice='en-US-JennyNeural',
    cta_text='Test',
    cta_url='https://test.com'
)
comp = VideoCompositor(brand)
print(f'VideoCompositor created with clips_to_close: {comp.clips_to_close}')
print(f'Has convert_to_vertical: {hasattr(comp, \"convert_to_vertical\")}')
"
```
  </verify>
  <done>convert_to_vertical method exists and returns VideoFileClip with 1080x1920 dimensions</done>
</task>

<task type="auto">
  <name>Task 3: Add cleanup method for memory management</name>
  <files>src/video/compositor.py</files>
  <action>
Add cleanup method and import gc at top of file:

```python
import gc
```

Add method:
```python
def cleanup(self) -> None:
    """Close all tracked clips to prevent memory leaks.

    CRITICAL: Must be called after write_videofile() completes.
    Failure to call this will cause memory to accumulate in batch processing.
    """
    for clip in self.clips_to_close:
        try:
            clip.close()
        except Exception:
            pass  # Ignore close errors - clip may already be closed
    self.clips_to_close.clear()
    gc.collect()
```

This is CRITICAL for Success Criteria #5 (memory cleanup across 10 consecutive generations).
  </action>
  <verify>
```bash
python -c "
from src.video import VideoCompositor
from src.models.brand import BrandConfig, ColorPalette
from pydantic_extra_types.color import Color

brand = BrandConfig(
    name='Test', slug='test',
    colors=ColorPalette(primary=Color('#000000'), secondary=Color('#FFFFFF')),
    tts_voice='en-US-JennyNeural', cta_text='Test', cta_url='https://test.com'
)
comp = VideoCompositor(brand)
comp.cleanup()  # Should run without error
print('cleanup() method works')
"
```
  </verify>
  <done>cleanup method exists, closes all clips, clears tracking list, and calls gc.collect()</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Module structure exists:
```bash
ls -la src/video/
# Should show __init__.py and compositor.py
```

2. VideoCompositor is importable and has all methods:
```bash
python -c "
from src.video import VideoCompositor
comp_class = VideoCompositor
methods = ['convert_to_vertical', 'cleanup']
for m in methods:
    assert hasattr(comp_class, m), f'Missing {m}'
print('All methods present')
"
```

3. Constants are defined:
```bash
python -c "
from src.video.compositor import VIDEO_WIDTH, VIDEO_HEIGHT, SAFE_ZONE_MARGIN, TARGET_FPS
assert VIDEO_WIDTH == 1080
assert VIDEO_HEIGHT == 1920
assert SAFE_ZONE_MARGIN == 120
assert TARGET_FPS == 24
print('Constants correct')
"
```
</verification>

<success_criteria>
- src/video/__init__.py exports VideoCompositor
- src/video/compositor.py contains VideoCompositor class
- VideoCompositor.__init__ accepts BrandConfig and initializes clips_to_close list
- convert_to_vertical method implements center-crop algorithm for 16:9 to 9:16
- cleanup method closes all clips and calls gc.collect()
- Module-level constants VIDEO_WIDTH, VIDEO_HEIGHT, SAFE_ZONE_MARGIN, TARGET_FPS are defined
- All imports use MoviePy 2.0 syntax (from moviepy import X, NOT from moviepy.editor)
</success_criteria>

<output>
After completion, create `.planning/phases/03-core-video-composition/03-01-SUMMARY.md`
</output>
